{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "from glob import glob\n",
    "from pymatreader import read_mat\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "import time\n",
    "\n",
    "#import matlab.engine\n",
    "# Test out matlab spike detection code\n",
    "#eng = matlab.engine.start_matlab()\n",
    "#eng.eval(\"startup\", nargout=0)\n",
    "\n",
    "# Importing custom python files\n",
    "import consts\n",
    "import importlib\n",
    "importlib.reload(consts)\n",
    "\n",
    "from open_ephys.analysis import Session\n",
    "\n",
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "# Get all of the ephys data and section everything across all trials\n",
    "def read_openephys_data(pathname, start_chan, frame_chan, stim_chan, flicker_chan):\n",
    "    session = Session(pathname)\n",
    "    ephys_data = session.recordnodes[0].recordings[0].continuous[0]\n",
    "\n",
    "    # Extract and find the start times of recording trials\n",
    "    start_chan_idx = ephys_data.metadata['channel_names'].index(start_chan)\n",
    "    raw_start_trigger = ephys_data.samples[:, start_chan_idx]\n",
    "\n",
    "    frame_chan_idx = ephys_data.metadata['channel_names'].index(frame_chan)\n",
    "    raw_frame_trigger = ephys_data.samples[:, frame_chan_idx]\n",
    "\n",
    "    stim_chan_idx = ephys_data.metadata['channel_names'].index(stim_chan)\n",
    "    raw_stim_trigger = ephys_data.samples[:, stim_chan_idx]\n",
    "\n",
    "    flicker_chan_idx = ephys_data.metadata['channel_names'].index(flicker_chan)\n",
    "    raw_flicker_trigger = ephys_data.samples[:, flicker_chan_idx]\n",
    "\n",
    "    # Get all of the rise idxs\n",
    "    record_start_idx = consts.get_ephys_rise_indices(raw_start_trigger)\n",
    "    all_frame_idx = consts.get_ephys_rise_indices(raw_frame_trigger)\n",
    "    all_stim_idx = consts.get_ephys_rise_indices(raw_stim_trigger)\n",
    "    all_flicker_idx = consts.get_ephys_rise_indices(raw_flicker_trigger)\n",
    "\n",
    "    # Get the reverse flicker idxs\n",
    "    #TODO fix this and try to get the reverse indices for the flicker and get the pulse width\n",
    "    all_flicker_end_idx = consts.get_ephys_rise_indices(raw_flicker_trigger)\n",
    "\n",
    "    block_frame_timestamps = []\n",
    "    block_stim_timestamps = []\n",
    "    block_flicker_timestamps = []\n",
    "\n",
    "    #DEBUG\n",
    "    #plt.figure()\n",
    "    #plt.plot(ephys_data.timestamps, raw_start_trigger)\n",
    "    #plt.plot(ephys_data.timestamps[record_start_idx], raw_start_trigger[record_start_idx], '|')\n",
    "    #plt.title('Ephys Debugging')\n",
    "    #plt.show()\n",
    "\n",
    "    #plt.figure()\n",
    "    #plt.plot(ephys_data.timestamps, raw_start_trigger, '-g')\n",
    "    #plt.plot(ephys_data.timestamps, raw_stim_trigger, '-g')\n",
    "    #plt.plot(ephys_data.timestamps, raw_flicker_trigger, '-b')\n",
    "\n",
    "    # Loop through each recording start trigger and parse together all of the trials\n",
    "    for i in range(record_start_idx.shape[0]):\n",
    "        start_idx = record_start_idx[i]\n",
    "        if i == record_start_idx.shape[0] - 1:\n",
    "            next_idx = float('inf')\n",
    "        else:\n",
    "            next_idx = record_start_idx[i + 1]\n",
    "\n",
    "        # Find all of the camera frame indices for the given block\n",
    "        frame_idxs = all_frame_idx[(all_frame_idx > start_idx) & (all_frame_idx < next_idx)]\n",
    "        stim_idxs = all_stim_idx[(all_stim_idx > start_idx) & (all_stim_idx < next_idx)]\n",
    "        flicker_idxs = all_flicker_idx[(all_flicker_idx > start_idx) & (all_flicker_idx < next_idx)]\n",
    "\n",
    "        block_frame_timestamps.append(ephys_data.timestamps[frame_idxs])\n",
    "        block_stim_timestamps.append(ephys_data.timestamps[stim_idxs])\n",
    "        block_flicker_timestamps.append(ephys_data.timestamps[flicker_idxs])\n",
    "    \n",
    "        #plt.plot(ephys_data.timestamps[stim_idxs], raw_stim_trigger[stim_idxs], '|r')\n",
    "        #plt.plot(ephys_data.timestamps[flicker_idxs], raw_flicker_trigger[flicker_idxs], '|r')\n",
    "        #plt.plot(ephys_data.timestamps[start_idx], raw_start_trigger[start_idx], '|m')\n",
    "    #plt.show()\n",
    "\n",
    "    return block_stim_timestamps, block_frame_timestamps, block_flicker_timestamps\n",
    "\n",
    "# Get the flicker experiment\n",
    "def get_param(fname, param):\n",
    "    # Loop through each element and search for string pattern\n",
    "    for exp_param in fname.split('_'):\n",
    "        if param in exp_param:\n",
    "            return exp_param    \n",
    "    print('Missing param: ' + param)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /home/pierfier/handata_server/eng_research_handata3/Yangyang_Wang/PV_V1_LED_SomArchon/109558_Vb_male/20240308/RawTracesV2_109558_20240308_flicker8hz_DBS140hz_fov1_100ua_red__all.mat\n",
      "Missing Corresponding Ephys Folder\n",
      "Matfile: RawTracesV2_109558_20240308_flicker8hz_DBS140hz_fov1_100ua_red__all.mat\n",
      "Using model ephys data\n",
      "1 /home/pierfier/handata_server/eng_research_handata3/Yangyang_Wang/PV_V1_LED_SomArchon/109558_Vb_male/20240308/RawTracesV2_109558_20240308_flicker8hz_DBS140hz_fov2_100ua_red__all.mat\n",
      "Missing Corresponding Ephys Folder\n",
      "Matfile: RawTracesV2_109558_20240308_flicker8hz_DBS140hz_fov2_100ua_red__all.mat\n",
      "Using model ephys data\n",
      "2 /home/pierfier/handata_server/eng_research_handata3/Yangyang_Wang/PV_V1_LED_SomArchon/109558_Vb_male/20240308/RawTracesV2_109558_20240308_flicker8hz_DBS140hz_fov3_100ua_red__all.mat\n",
      "Missing Corresponding Ephys Folder\n",
      "Matfile: RawTracesV2_109558_20240308_flicker8hz_DBS140hz_fov3_100ua_red__all.mat\n",
      "Using model ephys data\n",
      "3 /home/pierfier/handata_server/eng_research_handata3/Yangyang_Wang/PV_V1_LED_SomArchon/109558_Vb_male/20240311/RawTracesV2_109558_20240311_flicker8hz_DBS140hz_fov2_110ua_red__all.mat\n",
      "4 /home/pierfier/handata_server/eng_research_handata3/Yangyang_Wang/PV_V1_LED_SomArchon/109558_Vb_male/20240311/RawTracesV2_109558_20240311_flicker8hz_DBS40hz_fov1_100ua_red__all.mat\n",
      "5 /home/pierfier/handata_server/eng_research_handata3/Yangyang_Wang/PV_V1_LED_SomArchon/109558_Vb_male/20240311/RawTracesV2_109558_20240311_flicker8hz_DBS40hz_fov3_110ua_red__all.mat\n",
      "6 /home/pierfier/handata_server/eng_research_handata3/Yangyang_Wang/PV_V1_LED_SomArchon/109558_Vb_male/20240311/RawTracesV2_109558_20240311_flicker8hz_DBS40hz_fov2_110ua_red__all.mat\n",
      "7 /home/pierfier/handata_server/eng_research_handata3/Yangyang_Wang/PV_V1_LED_SomArchon/109558_Vb_male/20240311/RawTracesV2_109558_20240311_flicker8hz_DBS140hz_fov3_110ua_red__all.mat\n",
      "8 /home/pierfier/handata_server/eng_research_handata3/Yangyang_Wang/PV_V1_LED_SomArchon/109558_Vb_male/20240311/RawTracesV2_109558_20240311_flicker8hz_DBS140hz_fov4_110ua_red__all.mat\n",
      "9 /home/pierfier/handata_server/eng_research_handata3/Yangyang_Wang/PV_V1_LED_SomArchon/109558_Vb_male/20240311/RawTracesV2_109558_20240311_flicker8hz_DBS140hz_fov1_100ua_red__all.mat\n",
      "10 /home/pierfier/handata_server/eng_research_handata3/Yangyang_Wang/PV_V1_LED_SomArchon/109558_Vb_male/20240311/RawTracesV2_109558_20240311_flicker8hz_DBS40hz_fov4_110ua_red__all.mat\n",
      "Removed trial stuff\n",
      "11 /home/pierfier/handata_server/eng_research_handata3/Yangyang_Wang/PV_V1_LED_SomArchon/109567_Vb_male/20240411/RawTracesV2_109567_20240411_flicker8hz_DBS140hz_fov1_170ua__all.mat\n",
      "12 /home/pierfier/handata_server/eng_research_handata3/Yangyang_Wang/PV_V1_LED_SomArchon/109567_Vb_male/20240411/RawTracesV2_109567_20240411_flicker8hz_DBS140hz_fov2_170ua__all.mat\n",
      "13 /home/pierfier/handata_server/eng_research_handata3/Yangyang_Wang/PV_V1_LED_SomArchon/109567_Vb_male/20240411/RawTracesV2_109567_20240411_flicker8hz_DBS140hz_fov3_170ua__all.mat\n",
      "14 /home/pierfier/handata_server/eng_research_handata3/Yangyang_Wang/PV_V1_LED_SomArchon/109567_Vb_male/20240411/RawTracesV2_109567_20240411_flicker8hz_DBS140hz_fov4_170ua__all.mat\n",
      "15 /home/pierfier/handata_server/eng_research_handata3/Yangyang_Wang/PV_V1_LED_SomArchon/109567_Vb_male/20240411/RawTracesV2_109567_20240411_flicker8hz_DBS140hz_fov5_170ua__all.mat\n",
      "16 /home/pierfier/handata_server/eng_research_handata3/Yangyang_Wang/PV_V1_LED_SomArchon/109567_Vb_male/20240411/RawTracesV2_109567_20240411_flicker8hz_DBS40hz_fov1_210ua__all.mat\n",
      "Missing Corresponding Ephys Folder\n",
      "Matfile: RawTracesV2_109567_20240411_flicker8hz_DBS40hz_fov1_210ua__all.mat\n",
      "Using model ephys data\n",
      "17 /home/pierfier/handata_server/eng_research_handata3/Yangyang_Wang/PV_V1_LED_SomArchon/109567_Vb_male/20240411/RawTracesV2_109567_20240411_flicker8hz_DBS40hz_fov2_210ua__all.mat\n",
      "Missing Corresponding Ephys Folder\n",
      "Matfile: RawTracesV2_109567_20240411_flicker8hz_DBS40hz_fov2_210ua__all.mat\n",
      "Using model ephys data\n",
      "18 /home/pierfier/handata_server/eng_research_handata3/Yangyang_Wang/PV_V1_LED_SomArchon/109567_Vb_male/20240411/RawTracesV2_109567_20240411_flicker8hz_DBS40hz_fov3_210ua__all.mat\n",
      "Missing Corresponding Ephys Folder\n",
      "Matfile: RawTracesV2_109567_20240411_flicker8hz_DBS40hz_fov3_210ua__all.mat\n",
      "Using model ephys data\n",
      "19 /home/pierfier/handata_server/eng_research_handata3/Yangyang_Wang/PV_V1_LED_SomArchon/109567_Vb_male/20240411/RawTracesV2_109567_20240411_flicker8hz_DBS40hz_fov4_210ua__all.mat\n",
      "Missing Corresponding Ephys Folder\n",
      "Matfile: RawTracesV2_109567_20240411_flicker8hz_DBS40hz_fov4_210ua__all.mat\n",
      "Using model ephys data\n",
      "20 /home/pierfier/handata_server/eng_research_handata3/Yangyang_Wang/PV_V1_LED_SomArchon/109567_Vb_male/20240411/RawTracesV2_109567_20240411_flicker8hz_DBS40hz_fov5_210ua__all.mat\n",
      "Missing Corresponding Ephys Folder\n",
      "Matfile: RawTracesV2_109567_20240411_flicker8hz_DBS40hz_fov5_210ua__all.mat\n",
      "Using model ephys data\n",
      "21 /home/pierfier/handata_server/eng_research_handata3/Yangyang_Wang/PV_V1_LED_SomArchon/109567_Vb_male/20240311/RawTracesV2_109567_20240311_flicker8hz_DBS140hz_fov2_160ua_red__all.mat\n",
      "22 /home/pierfier/handata_server/eng_research_handata3/Yangyang_Wang/PV_V1_LED_SomArchon/109567_Vb_male/20240311/RawTracesV2_109567_20240311_flicker8hz_DBS40hz_fov1_210ua_red__all.mat\n",
      "23 /home/pierfier/handata_server/eng_research_handata3/Yangyang_Wang/PV_V1_LED_SomArchon/109567_Vb_male/20240311/RawTracesV2_109567_20240311_flicker8hz_DBS40hz_fov3_210ua_red__all.mat\n",
      "24 /home/pierfier/handata_server/eng_research_handata3/Yangyang_Wang/PV_V1_LED_SomArchon/109567_Vb_male/20240311/RawTracesV2_109567_20240311_flicker8hz_DBS40hz_fov2_210ua_red__all.mat\n",
      "25 /home/pierfier/handata_server/eng_research_handata3/Yangyang_Wang/PV_V1_LED_SomArchon/109567_Vb_male/20240311/RawTracesV2_109567_20240311_flicker8hz_DBS140hz_fov4_170ua_red__all.mat\n",
      "26 /home/pierfier/handata_server/eng_research_handata3/Yangyang_Wang/PV_V1_LED_SomArchon/109567_Vb_male/20240311/RawTracesV2_109567_20240311_flicker8hz_DBS40hz_fov4_210ua_red__all.mat\n",
      "27 /home/pierfier/handata_server/eng_research_handata3/Yangyang_Wang/PV_V1_LED_SomArchon/109567_Vb_male/20240311/RawTracesV2_109567_20240311_flicker8hz_DBS140hz_fov6_170ua_red__all.mat\n",
      "28 /home/pierfier/handata_server/eng_research_handata3/Yangyang_Wang/PV_V1_LED_SomArchon/109567_Vb_male/20240311/RawTracesV2_109567_20240311_flicker8hz_DBS40hz_fov5_210ua_red__all.mat\n",
      "29 /home/pierfier/handata_server/eng_research_handata3/Yangyang_Wang/PV_V1_LED_SomArchon/109567_Vb_male/20240311/RawTracesV2_109567_20240311_flicker8hz_DBS140hz_fov5_170ua_red__all.mat\n",
      "30 /home/pierfier/handata_server/eng_research_handata3/Yangyang_Wang/PV_V1_LED_SomArchon/109567_Vb_male/20240311/RawTracesV2_109567_20240311_flicker8hz_DBS40hz_fov6_210ua_red__all.mat\n",
      "31 /home/pierfier/handata_server/eng_research_handata3/Yangyang_Wang/PV_V1_LED_SomArchon/109567_Vb_male/20240311/RawTracesV2_109567_20240311_flicker8hz_DBS140hz_fov1_160ua_red__all.mat\n",
      "32 /home/pierfier/handata_server/eng_research_handata3/Yangyang_Wang/PV_V1_LED_SomArchon/109567_Vb_male/20240424/RawTracesV2_109567_20240424_flicker8hz_DBS40hz_fov3_210ua__all.mat\n",
      "33 /home/pierfier/handata_server/eng_research_handata3/Yangyang_Wang/PV_V1_LED_SomArchon/109567_Vb_male/20240424/RawTracesV2_109567_20240424_flicker8hz_DBS140hz_fov4_170ua__all.mat\n",
      "34 /home/pierfier/handata_server/eng_research_handata3/Yangyang_Wang/PV_V1_LED_SomArchon/109567_Vb_male/20240424/RawTracesV2_109567_20240424_flicker8hz_DBS40hz_fov4_210ua__all.mat\n",
      "35 /home/pierfier/handata_server/eng_research_handata3/Yangyang_Wang/PV_V1_LED_SomArchon/109567_Vb_male/20240424/RawTracesV2_109567_20240424_flicker8hz_DBS140hz_fov3_170ua__all.mat\n",
      "36 /home/pierfier/handata_server/eng_research_handata3/Yangyang_Wang/PV_V1_LED_SomArchon/109567_Vb_male/20240424/RawTracesV2_109567_20240424_flicker8hz_DBS40hz_fov2_210ua__all.mat\n"
     ]
    }
   ],
   "source": [
    "f = os.sep\n",
    "\n",
    "# Initialize empty dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Data rootpath is actually in handata3 for now\n",
    "server_root = '/home/pierfier/handata_server/eng_research_handata3'\n",
    "data_root_path = f.join([server_root, 'Yangyang_Wang', 'PV_V1_LED_SomArchon']) + f\n",
    "\n",
    "# Find all folders that have the traces matfile and were flicker experiments\n",
    "mat_paths = glob(data_root_path + '**/**RawTraces**flicker**DBS**.mat', recursive=True)\n",
    "\n",
    "# Ignore matfiles that are in archive files\n",
    "fun = lambda s: 'archive' not in s.lower()\n",
    "mat_paths = list(filter(fun, mat_paths))\n",
    "\n",
    "# Set an amount of frames to drop in front of the traces\n",
    "front_frame_drop = 14\n",
    "\n",
    "# Loop through each matfile that contains\n",
    "not_aligned = []\n",
    "for mat_i, mat_path in enumerate(mat_paths): #TODO DEBUG mat_paths:    \n",
    "    print(str(mat_i) +' '+ mat_path)\n",
    "\n",
    "    #Get the current experiments data \n",
    "    cur_flicker = get_param(os.path.basename(mat_path), 'flicker')\n",
    "    cur_freq = get_param(os.path.basename(mat_path), 'DBS')\n",
    "    cur_fov = get_param(os.path.basename(mat_path), 'fov')\n",
    "\n",
    "    # Set the experimental parameters into variables\n",
    "    cur_stim_freq = int(cur_freq.replace('DBS', '').replace('hz', ''))\n",
    "    cur_flicker_freq = int(cur_flicker.replace('flicker', '').replace('hz', ''))\n",
    "    session_id = os.path.basename(os.path.dirname(mat_path))\n",
    "    mouse_id = os.path.basename(os.path.dirname(os.path.dirname(mat_path)))\n",
    "    stim_param_string = 'currentamp:' + get_param(os.path.basename(mat_path), 'ua') \n",
    "\n",
    "    #Find corresponding experiment openephys data\n",
    "    ephys_dir = f.join([os.path.dirname(mat_path), 'ephys']) + f\n",
    "    ephys_path = glob(ephys_dir + '*' + cur_flicker + '*' + \\\n",
    "                        cur_freq + '*' + cur_fov + '*')\n",
    "    if not ephys_path:\n",
    "        #TODO read in model ephys folder, depending on stim frequency\n",
    "        print('Missing Corresponding Ephys Folder')\n",
    "        print('Matfile: ' + os.path.basename(mat_path))\n",
    "        print('Using model ephys data')\n",
    "        #continue\n",
    "        ephys_path = glob('.'+f+ '*' + cur_flicker + '*' + \\\n",
    "                        cur_freq + '*')\n",
    "\n",
    "    if len(ephys_path) > 1:\n",
    "        print('There are multiple ephys_path\\'s with this experiment')\n",
    "        not_aligned = not_aligned.append(mat_path)\n",
    "        continue\n",
    "\n",
    "    # Read in all of the Open Ephys data\n",
    "    #1 are the frames\n",
    "    #3 are the flicker pulses\n",
    "    #4 are the stim pulses\n",
    "    #5 are the trial start triggers\n",
    "    stim_timestamps, frame_timestamps, flicker_timestamps = \\\n",
    "        read_openephys_data(pathname=ephys_path[0], start_chan='ADC5', frame_chan='ADC1', \\\n",
    "                            stim_chan='ADC4', flicker_chan='ADC3')\n",
    "\n",
    "    # Read in trace data\n",
    "    data = read_mat(mat_path)\n",
    "    sp_info = data['spike_detect_SA_v4_info']\n",
    "    data = data['roi_list']\n",
    "\n",
    "    #TODO figure out how to check if there are multiple neuron traces\n",
    "    if len(data['traces'].shape) < 2:\n",
    "        data['traces'] = data['traces'].reshape(-1, 1)\n",
    "\n",
    "    # If there are more voltage trial traces than ephys start triggers,\n",
    "    # Just duplicate it again\n",
    "    if len(sp_info) > len(frame_timestamps):\n",
    "        frame_timestamps.extend(frame_timestamps)\n",
    "        stim_timestamps.extend(stim_timestamps)\n",
    "        flicker_timestamps.extend(flicker_timestamps)\n",
    "\n",
    "    for roi_i in range(data['traces'].shape[1]):\n",
    "\n",
    "        # Loop through each trial\n",
    "        for trial_i in range(len(sp_info)):\n",
    "            #TODO need to figure out a way to skip this trial during alignment\n",
    "            # Maybe try to remove that index ephys information across all of its arrays\n",
    "\n",
    "            # Delete trial elements that do not have the same amount \n",
    "            while len(frame_timestamps[trial_i]) < 1:\n",
    "                print('Removed trial stuff')\n",
    "                frame_timestamps.pop(trial_i)\n",
    "                stim_timestamps.pop(trial_i)\n",
    "\n",
    "                flicker_timestamps.pop(trial_i)\n",
    "            \n",
    "            cur_frame_time = frame_timestamps[trial_i][front_frame_drop:]\n",
    "\n",
    "            raw_trace = data['traces'][np.where(data['trial_vec'] == trial_i + 1)[0], roi_i]\n",
    "            raw_trace = raw_trace[front_frame_drop:]\n",
    "\n",
    "            cur_trace_noise = sp_info[trial_i*(data['traces'].shape[1]) + roi_i]['trace_noise'][front_frame_drop:]\n",
    "\n",
    "            # Grab the first number set of camera frames as the trace\n",
    "            cur_frame_time = cur_frame_time[:raw_trace.shape[0]]\n",
    "            cur_stim_time = stim_timestamps[trial_i]\n",
    "            trial_start = cur_frame_time[0]\n",
    "            stim_start = cur_stim_time[0]\n",
    "\n",
    "            cur_frame_time = cur_frame_time - trial_start\n",
    "            cur_stim_time = cur_stim_time - trial_start\n",
    "            cur_flicker_time = flicker_timestamps[trial_i] - trial_start\n",
    "\n",
    "            # Grab the original spike detection data\n",
    "            cur_spike_raster = np.zeros_like(raw_trace)\n",
    "            spike_idx = sp_info[trial_i*(data['traces'].shape[1]) + roi_i]['spike_idx']\n",
    "            if isinstance(spike_idx, int):\n",
    "                spike_idx = np.array([spike_idx])\n",
    "\n",
    "            spike_idx = spike_idx[np.where(spike_idx >= front_frame_drop + 1)]\n",
    "\n",
    "            cur_spike_raster[spike_idx - front_frame_drop - 1] = 1\n",
    "\n",
    "            # Define the 'interp_time' and interpolate all of the data\n",
    "            #TODO need to change how the interpolation is done here\n",
    "            #ideal_trial_end\n",
    "            #TODO this also messes up the flicker and stim raster stuff for some reasons\n",
    "            step = 1/500\n",
    "            interp_time = np.arange(0, raw_trace.shape[0]*step, step) \n",
    "            # Old method that did not really take into account the idealized frequency\n",
    "            #interp_time = np.linspace(0, cur_frame_time[-1] - cur_frame_time[0], raw_trace.shape[0])\n",
    "            interp_raw_trace = np.interp(interp_time, cur_frame_time, raw_trace)\n",
    "            interp_spike_raster = np.interp(interp_time, cur_frame_time, cur_spike_raster)\n",
    "\n",
    "            # Interpolate subthreshold Vm, with spikes removed\n",
    "            sub_vm = sp_info[trial_i*(data['traces'].shape[1]) + roi_i]['trace_spikeRemoved'][front_frame_drop:]\n",
    "            interp_subvm = np.interp(interp_time, cur_frame_time, sub_vm)\n",
    "\n",
    "            # Interpolated the detrended raw trace \n",
    "            #(this is from the quick_trial_check.m moving window average before spike detection)\n",
    "            detrend_trace = sp_info[trial_i*(data['traces'].shape[1]) + roi_i]['trace_raw'][front_frame_drop:]\n",
    "            interp_raw_detrend_trace = np.interp(interp_time, cur_frame_time, detrend_trace)\n",
    "\n",
    "            # Adjusted spike index\n",
    "            peak_idx, _ = signal.find_peaks(interp_spike_raster)\n",
    "            interp_spike_raster_adj = np.zeros(interp_raw_trace.shape)\n",
    "            interp_spike_raster_adj[peak_idx] = 1\n",
    "\n",
    "            # Create a spike amplitude raster\n",
    "            spike_amp_raster = np.full(interp_raw_trace.shape, np.nan)\n",
    "            spike_amp = sp_info[trial_i*(data['traces'].shape[1]) + roi_i]['spike_amplitude']            \n",
    "            \n",
    "            if not isinstance(spike_amp, np.ndarray):\n",
    "                spike_amp = np.array([spike_amp])\n",
    "\n",
    "            spike_amp = spike_amp[spike_amp.shape[0] - spike_idx.shape[0]:]\n",
    "            spike_amp = spike_amp[:np.min([np.where(interp_spike_raster_adj == 1)[0].shape[0], spike_amp.shape[0]])]\n",
    "            spike_amp_raster[np.where(interp_spike_raster_adj == 1)[0]] = spike_amp\n",
    "\n",
    "            # Create stimulation raster\n",
    "            cur_stim_raster = np.zeros(raw_trace.shape[0])\n",
    "            diff_mat = [interp_time] - np.transpose([cur_stim_time])\n",
    "            diff_mat[diff_mat < 0] = float('inf')\n",
    "            stim_idx_i = np.argmin(diff_mat, axis=1)\n",
    "            cur_stim_raster[stim_idx_i] = 1\n",
    "\n",
    "            # Create flicker raster\n",
    "            # Calculate the light duration for 1Hz\n",
    "            # TODO will need to eventually adjust this maybe?\n",
    "            cur_flicker_raster = np.zeros(raw_trace.shape[0])\n",
    "            diff_mat = [interp_time] - np.transpose([cur_flicker_time])\n",
    "            diff_mat[diff_mat < 0] = float('inf')\n",
    "            flicker_idx_i = np.argmin(diff_mat, axis=1)\n",
    "            cur_flicker_raster[flicker_idx_i] = 1\n",
    "            flick_dur = 0.06256 # Calculated one time\n",
    "            flick_pts = flick_dur/np.mean(np.diff(cur_frame_time))\n",
    "\n",
    "            # Adjust the interpolated time from the flicker onset here?\n",
    "            flicker_start = interp_time[np.where(cur_flicker_raster == 1)[0][0]]\n",
    "            interp_time = interp_time - flicker_start\n",
    "                        \n",
    "            #DEBUG\n",
    "            #plt.figure()\n",
    "            #plt.plot(interp_time, cur_flicker_raster, label='Flicker Raster')\n",
    "            #plt.plot(flicker_start, 1, '|', label='Flicker Start')\n",
    "            #plt.show()\n",
    "            #if mat_i == 1:\n",
    "            #    raise Exception(\"Stopping execution\")\n",
    "\n",
    "            mask = np.zeros(cur_flicker_raster.shape[0])\n",
    "\n",
    "            #Construct mask for flicker\n",
    "            for i in np.where(cur_flicker_raster == 1)[0]:\n",
    "                mask[np.arange(i, i + flick_pts + 1, dtype=int)] = 1\n",
    "            mask = mask.astype(bool)\n",
    "            cur_flicker_raster[mask] = 1\n",
    "\n",
    "            trace_dict = {'frame_time':cur_frame_time,\n",
    "                          'interp_time':interp_time,\n",
    "                          'raw_trace':raw_trace,\n",
    "                          'sub_vm':sub_vm,\n",
    "                          'detrend_trace':detrend_trace,\n",
    "                          'interp_subvm':interp_subvm,\n",
    "                          'trace_noise':cur_trace_noise,\n",
    "                          'interp_raw_trace':interp_raw_trace,\n",
    "                          'interp_raw_detrend_trace':interp_raw_detrend_trace,\n",
    "                          'spike_raster':cur_spike_raster,\n",
    "                          'interp_spike_raster':interp_spike_raster_adj,\n",
    "                          'spike_amp_raster':spike_amp_raster,\n",
    "                          'flicker_raster':cur_flicker_raster,\n",
    "                          'stim_raster':cur_stim_raster,\n",
    "                          'stim_freq':cur_stim_freq,\n",
    "                          'flicker_freq':cur_flicker_freq,\n",
    "                          'stim_param':stim_param_string,\n",
    "                          'mouse_id':mouse_id,\n",
    "                          'session_id':session_id,\n",
    "                          'trial_id':trial_i,\n",
    "                          'fov_id':int(cur_fov.replace('fov', '')),\n",
    "                          'roi_id':roi_i,                          \n",
    "                          }\n",
    "            \n",
    "            df = pd.concat([df, pd.DataFrame(trace_dict)], ignore_index=True, join='outer')\n",
    "\n",
    "            df['stim_freq'] = df['stim_freq'].astype('category')\n",
    "            df['mouse_id'] = df['mouse_id'].astype('category')\n",
    "            df['session_id'] = df['session_id'].astype('category')\n",
    "\n",
    "# Print the not aligned matfiles\n",
    "if not not not_aligned:\n",
    "    print('Not aligned Matfiles')\n",
    "    for mf in not_aligned:\n",
    "        print(mf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n",
    "df['mouse_id'].unique()\n",
    "df['fov_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "[0.01003602 0.0072997  0.00822962 0.00915412 0.0085015  0.0065599\n",
      " 0.00791407 0.00712737 0.00542821 0.00637546 0.00936654 0.00662582\n",
      " 0.00758872 0.00778126 0.00617549 0.0076527  0.00825255 0.00649919\n",
      " 0.00789477 0.00569096 0.00659793]\n",
      "[ 693  701  723 1085 1202 1244 1273 1277 1421 1434 1711 1797 1838 1860\n",
      " 1884 1964 2069 2107 2155 2163 2222]\n",
      "[ 704  712  734 1094 1211 1253 1281 1285 1429 1442 1717 1803 1844 1865\n",
      " 1889 1969 2073 2111 2159 2167 2226]\n"
     ]
    }
   ],
   "source": [
    "print(np.min([np.where(interp_spike_raster_adj == 1)[0].shape[0], spike_amp.shape[0]]) + 1)\n",
    "print(spike_amp)\n",
    "print(np.where(interp_spike_raster_adj == 1)[0])\n",
    "print(spike_idx)\n",
    "plt.figure()\n",
    "plt.plot(cur_frame_time, cur_spike_raster)\n",
    "plt.plot(interp_time, interp_spike_raster_adj)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out which trials to remove\n",
    "ignore_trials = {\n",
    "    '109558_Vb_male':{\n",
    "        '20240311':{\n",
    "            1:{40:[3, 4, 5, 8, 10],\n",
    "               140:[1, 2, 8, 9]},\n",
    "            2:{40:[4, 5, 7, 8, 9, 10],\n",
    "               140:[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]},\n",
    "            3:{40:[1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "               140:[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]},\n",
    "            4:{40:[1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "               140:[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
    "         },\n",
    "         '20240308':{\n",
    "             1:{140:[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]},\n",
    "             2:{140:[2, 5, 6, 8, 9, 10, 11, 14, 16, 17, 18, 19]},\n",
    "             3:{140:[6, 7, 14, 15, 16]}\n",
    "         }\n",
    "    },\n",
    "    '109567_Vb_male':{\n",
    "        '20240311':{\n",
    "            1:{40:[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
    "               140:[4, 8, 9]}, \n",
    "            2:{40:[3, 5, 6, 7, 8],\n",
    "               140:[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]},\n",
    "            3:{40:[1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "               140:[]},\n",
    "            4:{40:[2, 3, 6, 7, 8, 9, 10],\n",
    "               140:[1, 2, 3, 4, 9, 10]},\n",
    "            5:{40:[7, 8, 9],\n",
    "               140:[1, 2, 3, 10]},\n",
    "            6:{40:[1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "               140:[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
    "        },\n",
    "        '20240411':{\n",
    "            1:{40:[6, 7, 8, 10],\n",
    "               140:[2, 3, 5, 8, 9, 10]},\n",
    "            2:{40:[1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "               140:[2, 3, 4, 5, 8, 9, 10]},\n",
    "            3:{40:[1, 6, 7, 8, 9],\n",
    "               140:[1, 3, 5]},\n",
    "            4:{40:[4, 5, 7, 9],\n",
    "               140:[7, 9, 10]},\n",
    "            5:{40:[1, 6, 7],\n",
    "               140:[1, 3, 4, 5, 6, 7]}\n",
    "        },\n",
    "        '20240424':{\n",
    "            2:{40:[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Loop through dictionary and remove from dataframe\n",
    "for m in ignore_trials.keys():\n",
    "    for s in ignore_trials[m].keys():\n",
    "        for fov in ignore_trials[m][s].keys():\n",
    "            for freq in ignore_trials[m][s][fov].keys():\n",
    "                df = df.drop(df[ (df['mouse_id'] == m) & \\\n",
    "                            (df['session_id'] == s) & \\\n",
    "                            (df['fov_id'] == fov) & \\\n",
    "                            (df['stim_freq'] == freq) & \\\n",
    "                (df['trial_id'].isin(np.array(ignore_trials[m][s][fov][freq]) - 1)) ].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(df[(df['mouse_id'] == '109567_Vb_male') & (df['session_id'] == '20240311') & \\\n",
    "         (df['fov_id'] == 6)]['trial_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data frame to pickle file\n",
    "save_filename = f + 'home' +f+ 'pierfier' +f+ 'Projects' +f+ 'Pierre Fabris' +f+ 'PV DBS neocortex' +f+ 'Interm_Data' +f+ 'flicker.pkl'\n",
    "df.to_pickle(save_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/pierfier/handata_server/eng_research_handata3/Yangyang_Wang/PV_V1_LED_SomArchon/109567_Vb_male/20240311/ephys/109567_flicker8hz_DBS140hz_fov1_12024-03-11_18-19-37_2']\n",
      "/home/pierfier/handata_server/eng_research_handata3/Yangyang_Wang/PV_V1_LED_SomArchon/109567_Vb_male/20240311/ephys/109567_flicker8hz_DBS140hz_fov1_12024-03-11_18-19-37_2\n"
     ]
    }
   ],
   "source": [
    "print(ephys_path)\n",
    "for path in ephys_path:\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "11\n",
      "10\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "print(len(frame_timestamps))\n",
    "print(len(flicker_timestamps))\n",
    "print(len(sp_info))\n",
    "print(trial_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfov_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[ (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfov_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m109558_Vb_male\u001b[39m\u001b[38;5;124m'\u001b[39m)])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "print(df['mouse_id'].unique())\n",
    "print(df['fov_id'].unique())\n",
    "print(df[ (df['fov_id'] == 1) & (df['mouse_id'] == '109558_Vb_male')])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
