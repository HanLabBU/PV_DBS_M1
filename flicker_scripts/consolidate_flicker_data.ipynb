{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "from glob import glob\n",
    "from pymatreader import read_mat\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "import time\n",
    "\n",
    "#import matlab.engine\n",
    "# Test out matlab spike detection code\n",
    "#eng = matlab.engine.start_matlab()\n",
    "#eng.eval(\"startup\", nargout=0)\n",
    "\n",
    "# Importing custom python files\n",
    "import consts\n",
    "import importlib\n",
    "importlib.reload(consts)\n",
    "\n",
    "from open_ephys.analysis import Session\n",
    "\n",
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "# Get all of the ephys data and section everything across all trials\n",
    "def read_openephys_data(pathname, start_chan, frame_chan, stim_chan, flicker_chan):\n",
    "    session = Session(pathname)\n",
    "    ephys_data = session.recordnodes[0].recordings[0].continuous[0]\n",
    "\n",
    "    # Extract and find the start times of recording trials\n",
    "    start_chan_idx = ephys_data.metadata['channel_names'].index(start_chan)\n",
    "    raw_start_trigger = ephys_data.samples[:, start_chan_idx]\n",
    "\n",
    "    frame_chan_idx = ephys_data.metadata['channel_names'].index(frame_chan)\n",
    "    raw_frame_trigger = ephys_data.samples[:, frame_chan_idx]\n",
    "\n",
    "    stim_chan_idx = ephys_data.metadata['channel_names'].index(stim_chan)\n",
    "    raw_stim_trigger = ephys_data.samples[:, stim_chan_idx]\n",
    "\n",
    "    flicker_chan_idx = ephys_data.metadata['channel_names'].index(flicker_chan)\n",
    "    raw_flicker_trigger = ephys_data.samples[:, flicker_chan_idx]\n",
    "\n",
    "    # Get all of the rise idxs\n",
    "    record_start_idx = consts.get_ephys_rise_indices(raw_start_trigger)\n",
    "    all_frame_idx = consts.get_ephys_rise_indices(raw_frame_trigger)\n",
    "    all_stim_idx = consts.get_ephys_rise_indices(raw_stim_trigger)\n",
    "    all_flicker_idx = consts.get_ephys_rise_indices(raw_flicker_trigger)\n",
    "\n",
    "    # Get the reverse flicker idxs\n",
    "    #TODO fix this and try to get the reverse indices for the flicker and get the pulse width\n",
    "    all_flicker_end_idx = consts.get_ephys_rise_indices(raw_flicker_trigger)\n",
    "\n",
    "    block_frame_timestamps = []\n",
    "    block_stim_timestamps = []\n",
    "    block_flicker_timestamps = []\n",
    "\n",
    "    #DEBUG\n",
    "    #plt.figure()\n",
    "    #plt.plot(ephys_data.timestamps, raw_start_trigger)\n",
    "    #plt.plot(ephys_data.timestamps[record_start_idx], raw_start_trigger[record_start_idx], '|')\n",
    "    #plt.title('Ephys Debugging')\n",
    "    #plt.show()\n",
    "\n",
    "    #plt.figure()\n",
    "    #plt.plot(ephys_data.timestamps, raw_start_trigger, '-g')\n",
    "    #plt.plot(ephys_data.timestamps, raw_stim_trigger, '-g')\n",
    "    #plt.plot(ephys_data.timestamps, raw_flicker_trigger, '-b')\n",
    "\n",
    "    # Loop through each recording start trigger and parse together all of the trials\n",
    "    for i in range(record_start_idx.shape[0]):\n",
    "        start_idx = record_start_idx[i]\n",
    "        if i == record_start_idx.shape[0] - 1:\n",
    "            next_idx = float('inf')\n",
    "        else:\n",
    "            next_idx = record_start_idx[i + 1]\n",
    "\n",
    "        # Find all of the camera frame indices for the given block\n",
    "        frame_idxs = all_frame_idx[(all_frame_idx > start_idx) & (all_frame_idx < next_idx)]\n",
    "        stim_idxs = all_stim_idx[(all_stim_idx > start_idx) & (all_stim_idx < next_idx)]\n",
    "        flicker_idxs = all_flicker_idx[(all_flicker_idx > start_idx) & (all_flicker_idx < next_idx)]\n",
    "\n",
    "        block_frame_timestamps.append(ephys_data.timestamps[frame_idxs])\n",
    "        block_stim_timestamps.append(ephys_data.timestamps[stim_idxs])\n",
    "        block_flicker_timestamps.append(ephys_data.timestamps[flicker_idxs])\n",
    "    \n",
    "        #plt.plot(ephys_data.timestamps[stim_idxs], raw_stim_trigger[stim_idxs], '|r')\n",
    "        #plt.plot(ephys_data.timestamps[flicker_idxs], raw_flicker_trigger[flicker_idxs], '|r')\n",
    "        #plt.plot(ephys_data.timestamps[start_idx], raw_start_trigger[start_idx], '|m')\n",
    "    #plt.show()\n",
    "\n",
    "    return block_stim_timestamps, block_frame_timestamps, block_flicker_timestamps\n",
    "\n",
    "# Get the flicker experiment\n",
    "def get_param(fname, param):\n",
    "    # Loop through each element and search for string pattern\n",
    "    for exp_param in fname.split('_'):\n",
    "        if param in exp_param:\n",
    "            return exp_param    \n",
    "    print('Missing param: ' + param)\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = os.sep\n",
    "\n",
    "# Initialize empty dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Data rootpath is actually in handata3 for now\n",
    "server_root = '/home/pierfier/handata_server/eng_research_handata3'\n",
    "data_root_path = f.join([server_root, 'Yangyang_Wang', 'PV_V1_LED_SomArchon']) + f\n",
    "\n",
    "# Find all folders that have the traces matfile and were flicker experiments\n",
    "mat_paths = glob(data_root_path + '**/**RawTraces**flicker**DBS**.mat', recursive=True)\n",
    "\n",
    "# Ignore matfiles that are in archive files\n",
    "fun = lambda s: 'archive' not in s.lower()\n",
    "mat_paths = list(filter(fun, mat_paths))\n",
    "\n",
    "# Set an amount of frames to drop in front of the traces\n",
    "front_frame_drop = 14\n",
    "\n",
    "# Loop through each matfile that contains\n",
    "not_aligned = []\n",
    "for mat_i, mat_path in enumerate(mat_paths): #TODO DEBUG mat_paths:    \n",
    "    print(str(mat_i) +' '+ mat_path)\n",
    "\n",
    "    #Get the current experiments data \n",
    "    cur_flicker = get_param(os.path.basename(mat_path), 'flicker')\n",
    "    cur_freq = get_param(os.path.basename(mat_path), 'DBS')\n",
    "    cur_fov = get_param(os.path.basename(mat_path), 'fov')\n",
    "\n",
    "    # Set the experimental parameters into variables\n",
    "    cur_stim_freq = int(cur_freq.replace('DBS', '').replace('hz', ''))\n",
    "    cur_flicker_freq = int(cur_flicker.replace('flicker', '').replace('hz', ''))\n",
    "    session_id = os.path.basename(os.path.dirname(mat_path))\n",
    "    mouse_id = os.path.basename(os.path.dirname(os.path.dirname(mat_path)))\n",
    "    stim_param_string = 'currentamp:' + get_param(os.path.basename(mat_path), 'ua') \n",
    "\n",
    "    #Find corresponding experiment openephys data\n",
    "    ephys_dir = f.join([os.path.dirname(mat_path), 'ephys']) + f\n",
    "    ephys_path = glob(ephys_dir + '*' + cur_flicker + '*' + \\\n",
    "                        cur_freq + '*' + cur_fov + '*')\n",
    "    if not ephys_path:\n",
    "        print('Missing Corresponding Ephys Folder')\n",
    "        print('Matfile: ' + os.path.basename(mat_path))\n",
    "        not_aligned = not_aligned.append(mat_path)\n",
    "        continue\n",
    "\n",
    "    if len(ephys_path) > 1:\n",
    "        print('There are multiple ephys_path\\'s with this experiment')\n",
    "        not_aligned = not_aligned.append(mat_path)\n",
    "        continue\n",
    "\n",
    "    # Read in all of the Open Ephys data\n",
    "    #1 are the frames\n",
    "    #3 are the flicker pulses\n",
    "    #4 are the stim pulses\n",
    "    #5 are the trial start triggers\n",
    "    stim_timestamps, frame_timestamps, flicker_timestamps = \\\n",
    "        read_openephys_data(pathname=ephys_path[0], start_chan='ADC5', frame_chan='ADC1', \\\n",
    "                            stim_chan='ADC4', flicker_chan='ADC3')\n",
    "\n",
    "    # Read in trace data\n",
    "    data = read_mat(mat_path)\n",
    "    sp_info = data['spike_detect_SA_v4_info']\n",
    "    data = data['roi_list']\n",
    "\n",
    "    #TODO figure out how to check if there are multiple neuron traces\n",
    "    if len(data['traces'].shape) < 2:\n",
    "        data['traces'] = data['traces'].reshape(-1, 1)\n",
    "    \n",
    "    for roi_i in range(data['traces'].shape[1]):\n",
    "\n",
    "        # Loop through each trial\n",
    "        for trial_i in range(len(sp_info)):\n",
    "            #TODO need to figure out a way to skip this trial during alignment\n",
    "            # Maybe try to remove that index ephys information across all of its arrays\n",
    "\n",
    "            # Delete trial elements that do not have the same amount \n",
    "            print(trial_i)\n",
    "            while len(frame_timestamps[trial_i]) < 1:\n",
    "                print('Removed trial stuff')\n",
    "                frame_timestamps.pop(trial_i)\n",
    "                stim_timestamps.pop(trial_i)\n",
    "                flicker_timestamps.pop(trial_i)\n",
    "            \n",
    "            cur_frame_time = frame_timestamps[trial_i][front_frame_drop:]\n",
    "            raw_trace = data['traces'][np.where(data['trial_vec'] == trial_i + 1)[0], roi_i]\n",
    "            raw_trace = raw_trace[front_frame_drop:]\n",
    "\n",
    "            # Grab the first number set of camera frames as the trace\n",
    "            cur_frame_time = cur_frame_time[:raw_trace.shape[0]]\n",
    "            block_start_time = cur_frame_time[0]\n",
    "\n",
    "            cur_frame_time = cur_frame_time - block_start_time\n",
    "            cur_stim_time = stim_timestamps[trial_i] - block_start_time\n",
    "            cur_flicker_time = flicker_timestamps[trial_i] - block_start_time\n",
    "            bl_range = cur_frame_time[-1] - cur_frame_time[0]\n",
    "\n",
    "            # Grab the original spike detection data\n",
    "            cur_spike_raster = np.zeros_like(raw_trace)\n",
    "            spike_idx = sp_info[trial_i*(data['traces'].shape[1]) + roi_i]['spike_idx']\n",
    "            if isinstance(spike_idx, int):\n",
    "                spike_idx = np.array([spike_idx])\n",
    "\n",
    "            spike_idx = spike_idx[np.where(spike_idx >= front_frame_drop + 1)]\n",
    "\n",
    "            cur_spike_raster[spike_idx - front_frame_drop - 1] = 1\n",
    "\n",
    "            # Define the 'interp_time' and interpolate all of the data\n",
    "            interp_time = np.linspace(0, np.floor(bl_range), raw_trace.shape[0])\n",
    "            interp_raw_trace = np.interp(interp_time, cur_frame_time, raw_trace)\n",
    "            interp_spike_raster = np.interp(interp_time, cur_frame_time, cur_spike_raster)\n",
    "\n",
    "            # Interpolate subthreshold Vm, with spikes removed\n",
    "            sub_vm = sp_info[trial_i*(data['traces'].shape[1]) + roi_i]['trace_spikeRemoved'][front_frame_drop:]\n",
    "            interp_subvm = np.interp(interp_time, cur_frame_time, sub_vm)\n",
    "\n",
    "            # Adjusted spike index\n",
    "            peak_idx, _ = signal.find_peaks(interp_spike_raster)\n",
    "            interp_spike_raster_adj = np.zeros(interp_raw_trace.shape)\n",
    "            interp_spike_raster_adj[peak_idx] = 1\n",
    "\n",
    "            # Create stimulation raster\n",
    "            cur_stim_raster = np.zeros(raw_trace.shape[0])\n",
    "            diff_mat = [interp_time] - np.transpose([cur_stim_time])\n",
    "            diff_mat[diff_mat < 0] = float('inf')\n",
    "            stim_idx_i = np.argmin(diff_mat, axis=1)\n",
    "            cur_stim_raster[stim_idx_i] = 1\n",
    "\n",
    "            # Create flicker raster\n",
    "            # Calculate the light duration for 1Hz\n",
    "            cur_flicker_raster = np.zeros(raw_trace.shape[0])\n",
    "            diff_mat = [interp_time] - np.transpose([cur_flicker_time])\n",
    "            diff_mat[diff_mat < 0] = float('inf')\n",
    "            flicker_idx_i = np.argmin(diff_mat, axis=1)\n",
    "            cur_flicker_raster[flicker_idx_i] = 1\n",
    "            flick_dur = 0.06256 # Calculated one time\n",
    "            flick_pts = flick_dur/np.mean(np.diff(cur_frame_time))\n",
    "\n",
    "            mask = np.zeros(cur_flicker_raster.shape[0])\n",
    "\n",
    "            #Construct mask for flicker\n",
    "            for i in np.where(cur_flicker_raster == 1)[0]:\n",
    "                mask[np.arange(i, i + flick_pts + 1, dtype=int)] = 1\n",
    "            mask = mask.astype(bool)\n",
    "            cur_flicker_raster[mask] = 1\n",
    "\n",
    "            trace_dict = {'frame_time':cur_frame_time,\n",
    "                          'raw_trace':raw_trace,\n",
    "                          'interp_time':interp_time,\n",
    "                          'interp_raw_trace':interp_raw_trace,\n",
    "                          'interp_spike_raster':interp_spike_raster_adj,\n",
    "                          'flicker_raster':cur_flicker_raster,\n",
    "                          'stim_raster':cur_stim_raster,\n",
    "                          'interp_subvm':interp_subvm,\n",
    "                          'stim_freq':cur_stim_freq,\n",
    "                          'flicker_freq':cur_flicker_freq,\n",
    "                          'mouse_id':mouse_id,\n",
    "                          'session_id':session_id,\n",
    "                          'trial_id':trial_i,\n",
    "                          'stim_param':stim_param_string,\n",
    "                          'fov_id':int(cur_fov.replace('fov', '')),\n",
    "                          'roi_id':roi_i\n",
    "                          }\n",
    "            \n",
    "            df = pd.concat([df, pd.DataFrame(trace_dict)], ignore_index=True, join='outer')\n",
    "\n",
    "            df['stim_freq'] = df['stim_freq'].astype('category')\n",
    "            df['mouse_id'] = df['mouse_id'].astype('category')\n",
    "            df['session_id'] = df['session_id'].astype('category')\n",
    "\n",
    "# Print the not aligned matfiles\n",
    "if not not not_aligned:\n",
    "    print('Not aligned Matfiles')\n",
    "    for mf in not_aligned:\n",
    "        print(mf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data frame to pickle file\n",
    "save_filename = f + 'home' +f+ 'pierfier' +f+ 'Projects' +f+ 'Pierre Fabris' +f+ 'PV DBS neocortex' +f+ 'Interm_Data' +f+ 'flicker.pkl'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ephys_path)\n",
    "for path in ephys_path:\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(frame_timestamps))\n",
    "print(len(flicker_timestamps))\n",
    "print(len(sp_info))\n",
    "print(trial_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['mouse_id'].unique())\n",
    "print(df['fov_id'].unique())\n",
    "print(df[ (df['fov_id'] == 1) & (df['mouse_id'] == '109558_Vb_male')])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
